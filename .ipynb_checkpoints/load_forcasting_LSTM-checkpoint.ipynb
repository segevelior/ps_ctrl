{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0186de75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import math\n",
    "from tensorflow.keras.layers import Concatenate, Dense, Activation, Dropout, Input, LSTM, Reshape, Lambda, RepeatVector, TimeDistributed, Flatten\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from functions import feature_extraction\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bed9044",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "AEP = pd.read_csv('AEP_hourly.csv')\n",
    "AEP = AEP.rename(columns={'AEP_MW': 'Load'})\n",
    "num_days_ago = 7\n",
    "num_hours_forecasting = 24\n",
    "features, data = feature_extraction(AEP, diff_in_hour=1, num_days_ago=num_days_ago, num_hours_forecasting=num_hours_forecasting,  test_split = 0.1, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a036a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparing\n",
    "\n",
    "x_train_seq = data['x_train_seq'].reshape(data['x_train_seq'].shape[0], data['x_train_seq'].shape[1],1)\n",
    "x_train_dt = data['x_train_dt']\n",
    "y_train = data['y_train'].reshape(data['y_train'].shape[0], data['y_train'].shape[1],1)\n",
    "x_val_seq = data['x_val_seq'].reshape(data['x_val_seq'].shape[0], data['x_val_seq'].shape[1],1)\n",
    "x_val_dt = data['x_val_dt']\n",
    "y_val = data['y_val']\n",
    "x_train_dt = x_train_dt.reshape((x_train_dt.shape[0], x_train_dt.shape[1], 1))\n",
    "x_val_dt = x_val_dt.reshape((x_val_dt.shape[0], x_val_dt.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdd246c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an LSTM Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93878be5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_days_ago * 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae526e35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 1, 9), (None, 24, 64)]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m datetime_repeated \u001b[38;5;241m=\u001b[39m RepeatVector(output_seq_len)(datetime_flattened)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Apply a dense layer to the every temporal slice of an input\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mConcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdatetime_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_outputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m decoder_dense \u001b[38;5;241m=\u001b[39m TimeDistributed(Dense(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     29\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m decoder_dense(decoder_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py39/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py39/lib/python3.9/site-packages/keras/layers/merging/concatenate.py:131\u001b[0m, in \u001b[0;36mConcatenate.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    125\u001b[0m unique_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m    126\u001b[0m     shape[axis]\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m shape \u001b[38;5;129;01min\u001b[39;00m shape_set\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shape[axis] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    129\u001b[0m )\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dims) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concatenation axis. Received: input_shape=[(None, 1, 9), (None, 24, 64)]"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "# Define parameters\n",
    "input_seq_len = num_days_ago * 24\n",
    "output_seq_len = num_hours_forecasting\n",
    "n_features = 1\n",
    "\n",
    "# Define the layers\n",
    "encoder_inputs = Input(shape=(input_seq_len, n_features))\n",
    "encoder = LSTM(64, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, which will use `encoder_states` as initial state.\n",
    "decoder_input = Input(shape=(input_seq_len, n_features))\n",
    "decoder_lstm = LSTM(64, return_sequences=True)\n",
    "decoder_outputs = decoder_lstm(RepeatVector(output_seq_len)(encoder_outputs), initial_state=encoder_states)\n",
    "\n",
    "#additional date and time input\n",
    "datetime_input = Input(shape=(1,x_train_dt.shape[1]))\n",
    "datetime_flattened = Flatten()(datetime_input)\n",
    "datetime_repeated = RepeatVector(output_seq_len)(datetime_flattened)\n",
    "\n",
    "# Apply a dense layer to the every temporal slice of an input\n",
    "\n",
    "decoder_outputs = Concatenate(axis=-1)([datetime_input, decoder_outputs])\n",
    "decoder_dense = TimeDistributed(Dense(1))\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "\n",
    "\n",
    "model = Model([encoder_inputs, datetime_input], decoder_outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcf249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.clear_session()\n",
    "# # Define parameters\n",
    "# input_seq_len = num_days_ago * 24\n",
    "# output_seq_len = num_hours_forecasting\n",
    "# input_seq_n_features = 1\n",
    "# input_seq_n_features = 1\n",
    "\n",
    "# n_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b01ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f44659",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit([x_train_seq, x_train_dt], y_train, batch_size=64, epochs=3, validation_data = ([x_val_seq, x_val_dt], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09648e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, len(history.history['loss'])+1),history.history['loss'], label='train loss')\n",
    "plt.plot(range(1, len(history.history['val_loss'])+1), history.history['val_loss'], label='validation loss')\n",
    "plt.scatter(range(1, len(history.history['loss'])+1),history.history['loss'])\n",
    "plt.scatter(range(1, len(history.history['val_loss'])+1), history.history['val_loss'])\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc08de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.array(model.predict([x_val_seq,x_val_dt]))\n",
    "y_hat = y_hat*data['std_value_load'] + data['mean_value_load']\n",
    "y = y_val*data['std_value_load'] + data['mean_value_load']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8214681",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1212\n",
    "\n",
    "print(f'y mean: {y.mean()}, y std: {y.std()}')\n",
    "print(f'y_hat mean: {y_hat.mean()}, y_hat std: {y_hat.std()}')\n",
    "\n",
    "y_plot_hat = y_hat[index,:]\n",
    "y_plot = y[index,:]\n",
    "\n",
    "plt.plot(range(len(y_plot_hat)), y_plot_hat, label='predicted load')\n",
    "plt.plot(range(len(y_plot)), y_plot, label='real load')\n",
    "plt.scatter(range(len(y_plot_hat)), y_plot_hat)\n",
    "plt.scatter(range(len(y_plot)), y_plot)\n",
    "plt.title('prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized load')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce9db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6bb27b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
